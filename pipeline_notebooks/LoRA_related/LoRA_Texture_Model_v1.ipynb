{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25243,
     "status": "ok",
     "timestamp": 1762244476927,
     "user": {
      "displayName": "Shahd Sumrain",
      "userId": "00027192328823674198"
     },
     "user_tz": -660
    },
    "id": "Zl0r5L2b3dnO",
    "outputId": "63d6c811-9a06-4d56-9025-cc7a81d77a0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pMQd3lLlwALn"
   },
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44606,
     "status": "ok",
     "timestamp": 1762244550105,
     "user": {
      "displayName": "Shahd Sumrain",
      "userId": "00027192328823674198"
     },
     "user_tz": -660
    },
    "id": "qINR_xravw7n",
    "outputId": "7ae9b657-6580-42a2-9bc3-1e33a4bfe607"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.1/315.1 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m108.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
      "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m/content/sd-scripts\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.4/302.4 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m131.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m97.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.8/825.8 kB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m813.6/813.6 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.7/92.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.5/417.5 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.6/240.6 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m123.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gradio 5.49.1 requires huggingface-hub<2.0,>=0.33.5, but you have huggingface-hub 0.24.5 which is incompatible.\n",
      "peft 0.17.1 requires huggingface_hub>=0.25.0, but you have huggingface-hub 0.24.5 which is incompatible.\n",
      "pymc 5.26.1 requires rich>=13.7.1, but you have rich 13.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "!pip -q install accelerate==0.33.0 bitsandbytes==0.43.1 safetensors==0.4.3 tensorboard\n",
    "!git clone -q https://github.com/kohya-ss/sd-scripts /content/sd-scripts\n",
    "%cd /content/sd-scripts\n",
    "!pip -q install -r requirements.txt\n",
    "\n",
    "# Your dataset made earlier:\n",
    "driveFolderPath = \"/content/drive/MyDrive/training_data/LoRA_Textures\"          # dataset matching required images/ and captions/ with .txt\n",
    "outputFolder  = \"/content/drive/MyDrive/outputs/LoRA_v1/\"      # where LoRA checkpoints go\n",
    "logDir  = \"/content/drive/MyDrive/outputs/LoRA_v1/log\" \n",
    "os.makedirs(driveFolderPath, exist_ok=True)\n",
    "os.makedirs(logDir, exist_ok=True)\n",
    "\n",
    "!mkdir -p \"$outputFolder\" \"$logDir\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7470,
     "status": "ok",
     "timestamp": 1762244574183,
     "user": {
      "displayName": "Shahd Sumrain",
      "userId": "00027192328823674198"
     },
     "user_tz": -660
    },
    "id": "u9TRprw1yx7w",
    "outputId": "efa26b01-8972-47ed-d1f3-bf5c1a12296a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.8.0+cu126\n",
      "numpy: 2.0.2\n",
      "opencv: 4.8.1\n",
      "diffusers: 0.25.0 transformers: 4.44.0\n"
     ]
    }
   ],
   "source": [
    "import torch, numpy as np, cv2, accelerate, safetensors\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"numpy:\", np.__version__)\n",
    "print(\"opencv:\", cv2.__version__)\n",
    "import diffusers, transformers\n",
    "print(\"diffusers:\", diffusers.__version__, \"transformers:\", transformers.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0flPvcGrw8_Q"
   },
   "source": [
    "paramaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1762244577364,
     "user": {
      "displayName": "Shahd Sumrain",
      "userId": "00027192328823674198"
     },
     "user_tz": -660
    },
    "id": "HvPVl2otw-VJ",
    "outputId": "1e11a7e4-e820-4fc3-cdd6-1e0abd930bd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for ~3500 steps, rank=8, LR=5e-05, batch=4, res=512,512\n"
     ]
    }
   ],
   "source": [
    "# adjusting for dataset size\n",
    "numImages = 114          \n",
    "if numImages <= 60:\n",
    "    maxSteps = 2500\n",
    "elif numImages <= 200:\n",
    "    maxSteps = 3500\n",
    "else:\n",
    "    maxSteps = 5000\n",
    "\n",
    "rank = 8                  # network_dim\n",
    "lr   = 5e-5               \n",
    "batch = 4                 \n",
    "res = \"512,512\"           # to match tiles\n",
    "\n",
    "print(f\"Training for ~{maxSteps} steps, rank={rank}, LR={lr}, batch={batch}, res={res}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-9tpodP1xIJp"
   },
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1480,
     "status": "ok",
     "timestamp": 1762244583997,
     "user": {
      "displayName": "Shahd Sumrain",
      "userId": "00027192328823674198"
     },
     "user_tz": -660
    },
    "id": "_zKLV1V47g7s",
    "outputId": "ca4fcb72-9bd1-4572-f5a2-029e71183c3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 57874\n",
      "-rw------- 1 root root 362195 Nov  4 06:59 asphalt_0_0.png\n",
      "-rw------- 1 root root     74 Nov  4 06:59 asphalt_0_0.txt\n",
      "-rw------- 1 root root 318034 Nov  4 06:59 asphalt_0_256.png\n",
      "-rw------- 1 root root     74 Nov  4 06:59 asphalt_0_256.txt\n",
      "-rw------- 1 root root 455582 Nov  4 06:59 asphalt_1_0_0.png\n",
      "-rw------- 1 root root     75 Nov  4 06:59 asphalt_1_0_0.txt\n",
      "-rw------- 1 root root 367734 Nov  4 06:59 asphalt_2_0_0.png\n",
      "-rw------- 1 root root     74 Nov  4 06:59 asphalt_2_0_0.txt\n",
      "-rw------- 1 root root 445659 Nov  4 06:59 asphalt_4_0_0.png\n",
      "-rw------- 1 root root     74 Nov  4 06:59 asphalt_4_0_0.txt\n",
      "-rw------- 1 root root 467551 Nov  4 06:59 asphalt_5_0_0.png\n",
      "-rw------- 1 root root     74 Nov  4 06:59 asphalt_5_0_0.txt\n",
      "-rw------- 1 root root 585771 Nov  4 06:59 asphalt_6_0_0.png\n",
      "-rw------- 1 root root     74 Nov  4 06:59 asphalt_6_0_0.txt\n",
      "-rw------- 1 root root 456607 Nov  4 07:00 building_1_0_0.png\n",
      "-rw------- 1 root root     55 Nov  4 07:00 building_1_0_0.txt\n",
      "-rw------- 1 root root 489786 Nov  4 07:00 building_4_0_0.png\n",
      "-rw------- 1 root root     55 Nov  4 07:00 building_4_0_0.txt\n",
      "-rw------- 1 root root 367934 Nov  4 07:01 buildings_0_0.png\n",
      "129\n",
      "129\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# checking if dataset setup properly i.e images and txts together\n",
    "ls -la \"/content/drive/MyDrive/training_data/LoRA_Textures/100_uavtex\" | head -n 20\n",
    "\n",
    "# checking how many of each to be the same (image and txt pairs)\n",
    "find \"/content/drive/MyDrive/training_data/LoRA_Textures/100_uavtex\" -type f -iname \"*.png\" | wc -l\n",
    "find \"/content/drive/MyDrive/training_data/LoRA_Textures/100_uavtex\" -type f -iname \"*.txt\"  | wc -l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4999,
     "status": "ok",
     "timestamp": 1762244596254,
     "user": {
      "displayName": "Shahd Sumrain",
      "userId": "00027192328823674198"
     },
     "user_tz": -660
    },
    "id": "YQKqFb2v8UtH",
    "outputId": "c4fd5fe1-1539-41f8-f289-e5ab253851bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate==0.30.0 in /usr/local/lib/python3.12/dist-packages (0.30.0)\n",
      "Collecting peft==0.10.0\n",
      "  Downloading peft-0.10.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.30.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.30.0) (25.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate==0.30.0) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate==0.30.0) (6.0.3)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.30.0) (2.8.0+cu126)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (from accelerate==0.30.0) (0.24.5)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.30.0) (0.4.2)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from peft==0.10.0) (4.44.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from peft==0.10.0) (4.67.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->accelerate==0.30.0) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->accelerate==0.30.0) (2025.3.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->accelerate==0.30.0) (2.32.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->accelerate==0.30.0) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (3.4.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->peft==0.10.0) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.12/dist-packages (from transformers->peft==0.10.0) (0.19.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.10.0->accelerate==0.30.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.30.0) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->accelerate==0.30.0) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->accelerate==0.30.0) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->accelerate==0.30.0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->accelerate==0.30.0) (2025.10.5)\n",
      "Downloading peft-0.10.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: peft\n",
      "  Attempting uninstall: peft\n",
      "    Found existing installation: peft 0.17.1\n",
      "    Uninstalling peft-0.17.1:\n",
      "      Successfully uninstalled peft-0.17.1\n",
      "Successfully installed peft-0.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U \"accelerate==0.30.0\" \"peft==0.10.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 49628,
     "status": "error",
     "timestamp": 1762244659479,
     "user": {
      "displayName": "Shahd Sumrain",
      "userId": "00027192328823674198"
     },
     "user_tz": -660
    },
    "id": "iaObdbxrxH3n",
    "outputId": "b753eb38-6176-442d-dff8-6122c17841bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accelerator device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_processes` was set to a value of `1`\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "/usr/local/lib/python3.12/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/usr/local/lib/python3.12/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "2025-11-04 08:23:42.871336: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762244622.892514    2911 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1762244622.899069    2911 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1762244622.915566    2911 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762244622.915591    2911 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762244622.915594    2911 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762244622.915597    2911 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "/usr/local/lib/python3.12/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/content/sd-scripts/library/custom_train_functions.py:172: SyntaxWarning: invalid escape sequence '\\('\n",
      "  \\( - literal character '('\n",
      "/content/sd-scripts/library/lpw_stable_diffusion.py:70: SyntaxWarning: invalid escape sequence '\\('\n",
      "  \\( - literal character '('\n",
      "2025-11-04 08:23:47 INFO     prepare tokenizer                train_util.py:4561\n",
      "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "2025-11-04 08:23:49 INFO     Using DreamBooth method.       train_network.py:172\n",
      "                    WARNING  ignore directory without repeats config_util.py:591\n",
      "                             /                                                  \n",
      "                             繰り返し回数のないディレクトリを                   \n",
      "                             無視します: images                                 \n",
      "                    WARNING  ignore directory without repeats config_util.py:591\n",
      "                             /                                                  \n",
      "                             繰り返し回数のないディレクトリを                   \n",
      "                             無視します: captions                               \n",
      "                    INFO     prepare images.                  train_util.py:1689\n",
      "                    INFO     found directory                  train_util.py:1636\n",
      "                             /content/drive/MyDrive/training_                   \n",
      "                             data/LoRA_Textures/100_uavtex                      \n",
      "                             contains 129 image files                           \n",
      "2025-11-04 08:23:55 INFO     12900 train images with          train_util.py:1730\n",
      "                             repeating.                                         \n",
      "                    INFO     0 reg images.                    train_util.py:1733\n",
      "                    WARNING  no regularization images /       train_util.py:1738\n",
      "                             正則化画像が見つかりませんでした                   \n",
      "                    INFO     [Dataset 0]                      config_util.py:572\n",
      "                               batch_size: 4                                    \n",
      "                               resolution: (512, 512)                           \n",
      "                               enable_bucket: True                              \n",
      "                               network_multiplier: 1.0                          \n",
      "                               min_bucket_reso: 256                             \n",
      "                               max_bucket_reso: 1024                            \n",
      "                               bucket_reso_steps: 64                            \n",
      "                               bucket_no_upscale: False                         \n",
      "                                                                                \n",
      "                               [Subset 0 of Dataset 0]                          \n",
      "                                 image_dir:                                     \n",
      "                             \"/content/drive/MyDrive/training                   \n",
      "                             _data/LoRA_Textures/100_uavtex\"                    \n",
      "                                 image_count: 129                               \n",
      "                                 num_repeats: 100                               \n",
      "                                 shuffle_caption: True                          \n",
      "                                 keep_tokens: 0                                 \n",
      "                                 keep_tokens_separator:                         \n",
      "                                 caption_separator: ,                           \n",
      "                                 secondary_separator: None                      \n",
      "                                 enable_wildcard: False                         \n",
      "                                 caption_dropout_rate: 0.0                      \n",
      "                                 caption_dropout_every_n_epoc                   \n",
      "                             hes: 0                                             \n",
      "                                 caption_tag_dropout_rate:                      \n",
      "                             0.0                                                \n",
      "                                 caption_prefix: None                           \n",
      "                                 caption_suffix: None                           \n",
      "                                 color_aug: False                               \n",
      "                                 flip_aug: False                                \n",
      "                                 face_crop_aug_range: None                      \n",
      "                                 random_crop: False                             \n",
      "                                 token_warmup_min: 1,                           \n",
      "                                 token_warmup_step: 0,                          \n",
      "                                 alpha_mask: False,                             \n",
      "                                 is_reg: False                                  \n",
      "                                 class_tokens: uavtex                           \n",
      "                                 caption_extension: .txt                        \n",
      "                                                                                \n",
      "                                                                                \n",
      "                    INFO     [Dataset 0]                      config_util.py:578\n",
      "                    INFO     loading image sizes.              train_util.py:901\n",
      "\r  0%|          | 0/129 [00:00<?, ?it/s]\r 43%|████▎     | 55/129 [00:00<00:00, 548.05it/s]\r 85%|████████▌ | 110/129 [00:00<00:00, 340.76it/s]\r100%|██████████| 129/129 [00:01<00:00, 122.04it/s]\n",
      "2025-11-04 08:23:56 INFO     make buckets                      train_util.py:907\n",
      "                    INFO     number of images (including       train_util.py:953\n",
      "                             repeats) /                                         \n",
      "                             各bucketの画像枚数（繰り返し回数                   \n",
      "                             を含む）                                           \n",
      "                    INFO     bucket 0: resolution (512, 512),  train_util.py:958\n",
      "                             count: 12900                                       \n",
      "                    INFO     mean ar error (without repeats):  train_util.py:966\n",
      "                             0.0                                                \n",
      "                    INFO     preparing accelerator          train_network.py:225\n",
      "                    INFO     loading model for process 0/1    train_util.py:4719\n",
      "                    INFO     load Diffusers pretrained        train_util.py:4681\n",
      "                             models:                                            \n",
      "                             runwayml/stable-diffusion-v1-5                     \n",
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "\rFetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]\rFetching 9 files:  11%|█         | 1/9 [00:00<00:03,  2.02it/s]\rFetching 9 files:  56%|█████▌    | 5/9 [00:02<00:01,  2.05it/s]\rFetching 9 files:  78%|███████▊  | 7/9 [00:17<00:06,  3.07s/it]\rFetching 9 files: 100%|██████████| 9/9 [00:17<00:00,  1.90s/it]\n",
      "\rLoading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]\rLoading pipeline components...:  20%|██        | 1/5 [00:00<00:00,  7.35it/s]\rLoading pipeline components...:  40%|████      | 2/5 [00:00<00:00,  4.08it/s]\rLoading pipeline components...: 100%|██████████| 5/5 [00:00<00:00,  9.76it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "2025-11-04 08:24:15 WARNING  Could not find the bitsandbytes    cextension.py:89\n",
      "                             CUDA binary at                                     \n",
      "                             PosixPath('/usr/local/lib/python3.                 \n",
      "                             12/dist-packages/bitsandbytes/libb                 \n",
      "                             itsandbytes_cuda126.so')                           \n",
      "                    WARNING  The installed version of           cextension.py:96\n",
      "                             bitsandbytes was compiled without                  \n",
      "                             GPU support. 8-bit optimizers,                     \n",
      "                             8-bit multiplication, and GPU                      \n",
      "                             quantization are unavailable.                      \n",
      "Traceback (most recent call last):\n",
      "  File \"/content/sd-scripts/train_network.py\", line 1250, in <module>\n",
      "    trainer.train(args)\n",
      "  File \"/content/sd-scripts/train_network.py\", line 234, in train\n",
      "    model_version, text_encoder, vae, unet = self.load_target_model(args, weight_dtype, accelerator)\n",
      "                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/content/sd-scripts/train_network.py\", line 101, in load_target_model\n",
      "    text_encoder, vae, unet, _ = train_util.load_target_model(args, weight_dtype, accelerator)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/content/sd-scripts/library/train_util.py\", line 4721, in load_target_model\n",
      "    text_encoder, vae, unet, load_stable_diffusion_format = _load_target_model(\n",
      "                                                            ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/content/sd-scripts/library/train_util.py\", line 4683, in _load_target_model\n",
      "    pipe = StableDiffusionPipeline.from_pretrained(name_or_path, tokenizer=None, safety_checker=None)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/diffusers/pipelines/pipeline_utils.py\", line 1363, in from_pretrained\n",
      "    model = pipeline_class(**init_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py\", line 237, in __init__\n",
      "    self.register_modules(\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/diffusers/pipelines/pipeline_utils.py\", line 569, in register_modules\n",
      "    not_compiled_module = _unwrap_model(module)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/diffusers/pipelines/pipeline_utils.py\", line 286, in _unwrap_model\n",
      "    from peft import PeftModel\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/peft/__init__.py\", line 22, in <module>\n",
      "    from .auto import (\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/peft/auto.py\", line 31, in <module>\n",
      "    from .config import PeftConfig\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/peft/config.py\", line 23, in <module>\n",
      "    from .utils import CONFIG_NAME, PeftType, TaskType\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/peft/utils/__init__.py\", line 21, in <module>\n",
      "    from .loftq_utils import replace_lora_weights_loftq\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/peft/utils/loftq_utils.py\", line 35, in <module>\n",
      "    import bitsandbytes as bnb\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/bitsandbytes/__init__.py\", line 15, in <module>\n",
      "    from .nn import modules\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/bitsandbytes/nn/__init__.py\", line 21, in <module>\n",
      "    from .triton_based_modules import (\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/bitsandbytes/nn/triton_based_modules.py\", line 7, in <module>\n",
      "    from bitsandbytes.triton.int8_matmul_mixed_dequantize import (\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/bitsandbytes/triton/int8_matmul_mixed_dequantize.py\", line 12, in <module>\n",
      "    from triton.ops.matmul_perf_model import early_config_prune, estimate_matmul_time\n",
      "ModuleNotFoundError: No module named 'triton.ops'\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/accelerate\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "             ^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/commands/accelerate_cli.py\", line 46, in main\n",
      "    args.func(args)\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/commands/launch.py\", line 1082, in launch_command\n",
      "    simple_launcher(args)\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/commands/launch.py\", line 688, in simple_launcher\n",
      "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
      "subprocess.CalledProcessError: Command '['/usr/bin/python3', 'train_network.py', '--pretrained_model_name_or_path=runwayml/stable-diffusion-v1-5', '--train_data_dir=/content/drive/MyDrive/training_data/LoRA_Textures', '--output_dir=/content/drive/MyDrive/outputs/LoRA_v1/', '--logging_dir=/content/drive/MyDrive/outputs/LoRA_v1/log', '--resolution=512,512', '--enable_bucket', '--network_module=networks.lora', '--network_dim=8', '--network_alpha=8', '--network_train_unet_only', '--optimizer_type=adamw8bit', '--learning_rate=5e-5', '--lr_scheduler=cosine_with_restarts', '--lr_warmup_steps=100', '--max_train_steps=3500', '--save_every_n_steps=500', '--train_batch_size=4', '--caption_extension=.txt', '--shuffle_caption', '--xformers', '--persistent_data_loader_workers', '--cache_latents']' returned non-zero exit status 1.\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'set -e\\ncd /content/sd-scripts\\n\\naccelerate launch --mixed_precision=bf16 train_network.py \\\\\\n  --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" \\\\\\n  --train_data_dir=\"/content/drive/MyDrive/training_data/LoRA_Textures\" \\\\\\n  --output_dir=\"/content/drive/MyDrive/outputs/LoRA_v1/\" \\\\\\n  --logging_dir=\"/content/drive/MyDrive/outputs/LoRA_v1/log\" \\\\\\n  --resolution=512,512 --enable_bucket \\\\\\n  --network_module=networks.lora \\\\\\n  --network_dim=8 --network_alpha=8 \\\\\\n  --network_train_unet_only \\\\\\n  --optimizer_type=adamw8bit \\\\\\n  --learning_rate=5e-5 \\\\\\n  --lr_scheduler=cosine_with_restarts --lr_warmup_steps=100 \\\\\\n  --max_train_steps=3500 \\\\\\n  --save_every_n_steps=500 \\\\\\n  --train_batch_size=4 \\\\\\n  --caption_extension=\".txt\" \\\\\\n  --shuffle_caption \\\\\\n  --xformers --persistent_data_loader_workers \\\\\\n  --cache_latents\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2765588689.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'set -e\\ncd /content/sd-scripts\\n\\naccelerate launch --mixed_precision=bf16 train_network.py \\\\\\n  --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" \\\\\\n  --train_data_dir=\"/content/drive/MyDrive/training_data/LoRA_Textures\" \\\\\\n  --output_dir=\"/content/drive/MyDrive/outputs/LoRA_v1/\" \\\\\\n  --logging_dir=\"/content/drive/MyDrive/outputs/LoRA_v1/log\" \\\\\\n  --resolution=512,512 --enable_bucket \\\\\\n  --network_module=networks.lora \\\\\\n  --network_dim=8 --network_alpha=8 \\\\\\n  --network_train_unet_only \\\\\\n  --optimizer_type=adamw8bit \\\\\\n  --learning_rate=5e-5 \\\\\\n  --lr_scheduler=cosine_with_restarts --lr_warmup_steps=100 \\\\\\n  --max_train_steps=3500 \\\\\\n  --save_every_n_steps=500 \\\\\\n  --train_batch_size=4 \\\\\\n  --caption_extension=\".txt\" \\\\\\n  --shuffle_caption \\\\\\n  --xformers --persistent_data_loader_workers \\\\\\n  --cache_latents\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-103>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'set -e\\ncd /content/sd-scripts\\n\\naccelerate launch --mixed_precision=bf16 train_network.py \\\\\\n  --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" \\\\\\n  --train_data_dir=\"/content/drive/MyDrive/training_data/LoRA_Textures\" \\\\\\n  --output_dir=\"/content/drive/MyDrive/outputs/LoRA_v1/\" \\\\\\n  --logging_dir=\"/content/drive/MyDrive/outputs/LoRA_v1/log\" \\\\\\n  --resolution=512,512 --enable_bucket \\\\\\n  --network_module=networks.lora \\\\\\n  --network_dim=8 --network_alpha=8 \\\\\\n  --network_train_unet_only \\\\\\n  --optimizer_type=adamw8bit \\\\\\n  --learning_rate=5e-5 \\\\\\n  --lr_scheduler=cosine_with_restarts --lr_warmup_steps=100 \\\\\\n  --max_train_steps=3500 \\\\\\n  --save_every_n_steps=500 \\\\\\n  --train_batch_size=4 \\\\\\n  --caption_extension=\".txt\" \\\\\\n  --shuffle_caption \\\\\\n  --xformers --persistent_data_loader_workers \\\\\\n  --cache_latents\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "set -e\n",
    "cd /content/sd-scripts\n",
    "\n",
    "accelerate launch --mixed_precision=bf16 train_network.py \\\n",
    "  --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" \\\n",
    "  --train_data_dir=\"/content/drive/MyDrive/training_data/LoRA_Textures\" \\\n",
    "  --output_dir=\"/content/drive/MyDrive/outputs/LoRA_v1/\" \\\n",
    "  --logging_dir=\"/content/drive/MyDrive/outputs/LoRA_v1/log\" \\\n",
    "  --resolution=512,512 --enable_bucket \\\n",
    "  --network_module=networks.lora \\\n",
    "  --network_dim=8 --network_alpha=8 \\\n",
    "  --network_train_unet_only \\\n",
    "  --optimizer_type=adamw8bit \\\n",
    "  --learning_rate=5e-5 \\\n",
    "  --lr_scheduler=cosine_with_restarts --lr_warmup_steps=100 \\\n",
    "  --max_train_steps=3500 \\\n",
    "  --save_every_n_steps=500 \\\n",
    "  --train_batch_size=4 \\\n",
    "  --caption_extension=\".txt\" \\\n",
    "  --shuffle_caption \\\n",
    "  --xformers --persistent_data_loader_workers \\\n",
    "  --cache_latents\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNukNZ98Bclmb2eTQESvG2y",
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
